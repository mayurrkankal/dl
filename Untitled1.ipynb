{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d005a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34cd9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3614c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ae049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca71463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a20cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53948c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,  \n",
    "                                   shear_range = 0.2,  \n",
    "                                   zoom_range = 0.2,  \n",
    "                                   horizontal_flip = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9997ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b56133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8eb1a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6252 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/HI/Desktop/mk/adultclassifier/adult/train',  \n",
    "                                                 target_size = (64, 64),  \n",
    "                                                 batch_size = 32,  \n",
    "                                                 class_mode = 'binary')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b47bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c36f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f4a0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('C:/Users/HI/Desktop/mk/adultclassifier/adult/test1',  \n",
    "                                            target_size = (64, 64),  \n",
    "                                            batch_size = 32,  \n",
    "                                            class_mode = 'binary')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c6adb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "289d30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part2: Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cbc40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc185ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71cba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87667f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf6468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa3dd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81104aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd700b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2: Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef6e4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ea7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c385300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d08e35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))  \n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031f823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d6d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step3: Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94a733e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc35b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a9a93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step4: Full Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c1480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8e7f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06adb106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7440b4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step5: Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a9da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a61f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40f17484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part3: Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf6795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "437d99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aec0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8f427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bb41b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the CNN on the Training set and evaluation on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9e445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f869011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "196/196 [==============================] - 49s 249ms/step - loss: 0.5391 - accuracy: 0.7281 - val_loss: 0.4725 - val_accuracy: 0.7830\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 48s 247ms/step - loss: 0.4287 - accuracy: 0.8111 - val_loss: 0.5615 - val_accuracy: 0.7614\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 48s 247ms/step - loss: 0.3912 - accuracy: 0.8313 - val_loss: 0.4728 - val_accuracy: 0.7867\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 48s 247ms/step - loss: 0.3560 - accuracy: 0.8410 - val_loss: 0.4826 - val_accuracy: 0.7905\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 48s 246ms/step - loss: 0.3408 - accuracy: 0.8559 - val_loss: 0.3935 - val_accuracy: 0.8246\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 48s 246ms/step - loss: 0.3145 - accuracy: 0.8682 - val_loss: 0.4064 - val_accuracy: 0.8193\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 48s 246ms/step - loss: 0.2945 - accuracy: 0.8799 - val_loss: 0.3963 - val_accuracy: 0.8288\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 48s 246ms/step - loss: 0.2748 - accuracy: 0.8855 - val_loss: 0.4056 - val_accuracy: 0.8264\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 48s 245ms/step - loss: 0.2674 - accuracy: 0.8890 - val_loss: 0.3995 - val_accuracy: 0.8253\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 48s 246ms/step - loss: 0.2586 - accuracy: 0.8959 - val_loss: 0.4139 - val_accuracy: 0.8340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27fb8f0a9e0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c183a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ee450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5da13676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part4: Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85380c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c11c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.utils as image\n",
    "\n",
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/na.jpg', target_size = (64, 64))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd6e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee9f666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35dc80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98ea7b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis = 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b2037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20b02a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    }
   ],
   "source": [
    "result = cnn.predict(test_image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f78fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9294e1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0, '2': 1}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6fd58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "903e7625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not adult\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:  \n",
    "  prediction = 'adult'  \n",
    "else:  \n",
    "  prediction = 'not adult'  \n",
    "  \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d855c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edd3d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will check for the other image which is of the adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f299a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "018f65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('C:/Users/HI/Desktop/mk/adultclassifier/adult/ad.jpg', target_size = (64, 64)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08f318e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f90de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis = 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfb5cb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "result = cnn.predict(test_image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67c7200c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:  \n",
    "  prediction = 'adult'  \n",
    "else:  \n",
    "  prediction = 'not adult'  \n",
    "  \n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa6a73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
